{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(path):\n",
    "    \"\"\" Reads input file from passed path and returns as numpy array. No\n",
    "    preprocessing is done. \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        data = np.array([l.strip() for l in f.readlines()])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_1_data = read_input(\"day_1/input.txt\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_positive_diff(arr):\n",
    "    \"\"\" Given an array, count how many 'next values' are higher then the previous value. \"\"\"\n",
    "    return sum((arr[1:] - arr[:-1]) > 0)\n",
    "\n",
    "\n",
    "def sum_by_window(arr, window_size=3):\n",
    "    \"\"\" Slides a window_size sized window over an array and calculates the sums of the windows. \"\"\"\n",
    "    return pd.Series(arr).rolling(window=window_size).sum().dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1692"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_positive_diff(day_1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate diff using sum of sliding window\n",
    "calc_positive_diff(sum_by_window(day_1_data, window_size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_2_data = read_input(\"day_2/input.txt\")\n",
    "\n",
    "# Split lines into command and values and converts the values into integers\n",
    "day_2_data = [[l[0], int(l[1])] for l in [line.split() for line in day_2_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250395"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos = 0\n",
    "y_pos = 0\n",
    "\n",
    "for command, value in day_2_data:\n",
    "    if command.startswith('f'):\n",
    "        x_pos += value\n",
    "    elif command.startswith('d'):\n",
    "        y_pos += value\n",
    "    elif command.startswith('u'):\n",
    "        y_pos -= value\n",
    "        \n",
    "x_pos * y_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1451210346"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos = 0\n",
    "y_pos = 0\n",
    "aim = 0\n",
    "\n",
    "for command, value in day_2_data:\n",
    "    if command.startswith('f'):\n",
    "        x_pos += value\n",
    "        y_pos += value * aim\n",
    "    elif command.startswith('d'):\n",
    "        aim += value\n",
    "    elif command.startswith('u'):\n",
    "        aim -= value\n",
    "        \n",
    "x_pos * y_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250395"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy solution part 1\n",
    "day_2_data = read_input(\"day_2/input.txt\")\n",
    "commands, values = zip(*[line.split() for line in day_2_data])\n",
    "# Turn into arrays for slicing possibilities\n",
    "commands = np.array(commands)\n",
    "values = np.array(values).astype(int)\n",
    "\n",
    "x_pos = values[commands == 'forward'].sum()\n",
    "y_pos = values[commands == 'down'].sum() - values[commands == 'up'].sum()\n",
    "x_pos * y_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_day_3_data():\n",
    "    day_3_data = read_input(\"day_3/input.txt\")\n",
    "\n",
    "    # Turn into numpy array, every bit on its own\n",
    "    day_3_data = np.array([[int(bit) for bit in bytes_] for bytes_ in day_3_data])\n",
    "    \n",
    "    return day_3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_3_data = load_day_3_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma is most commit bit per 'column'\n",
    "gamma = np.array([np.argmax(np.bincount(day_3_data[:, i])) for i in range(day_3_data.shape[1])])\n",
    "\n",
    "# Epsilon is least common bit per column, so the opposite of the gamma\n",
    "epsilon = 1 - np.array(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_array_to_int(arr):\n",
    "    return int(''.join(arr.astype(str)), base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform binary to number\n",
    "gamma = byte_array_to_int(gamma)\n",
    "epsilon = byte_array_to_int(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458194"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer is gamma times epsilon\n",
    "gamma * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_3_data = load_day_3_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_3_part_2(data, filter_by='max'):\n",
    "    assert filter_by in ['min', 'max']\n",
    "    \n",
    "    if filter_by == 'min':\n",
    "        default = 0\n",
    "        min_max_func = np.argmin\n",
    "    else:\n",
    "        default = 1\n",
    "        min_max_func = np.argmax\n",
    "    \n",
    "    for idx in range(data.shape[1]):\n",
    "        count = np.bincount(data[:, idx])\n",
    "        if len(set(count)) > 1 or len(set(data[:, idx])) == 1:\n",
    "            mcv = min_max_func(count)\n",
    "        # Value if column contains the same amount of both values\n",
    "        else:\n",
    "            mcv = default\n",
    "\n",
    "        # Remove rows where value of current index is not the most common value\n",
    "        data = data[data[:, idx] == mcv]\n",
    "        if data.shape[0] <= 1:\n",
    "            break\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen_rating = byte_array_to_int(day_3_part_2(day_3_data, filter_by='max')[0])\n",
    "co2_rating = byte_array_to_int(day_3_part_2(day_3_data, filter_by='min')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2829354"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxygen_rating * co2_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('day_4/input.txt', 'r') as f:\n",
    "    input_data = f.readlines()\n",
    "    # Split comma separated string of numbers to list and parse all\n",
    "    # string numbers to ints\n",
    "    numbers = [int(i) for i in input_data[0].strip().split(',')]\n",
    "    # The rest of the data are the bingo cards\n",
    "    bingo_cards = [line.strip().split() for line in input_data[2:] if line != '\\n']  # Remove empty lines\n",
    "    \n",
    "    # Using reshape get a 3d array of N 5 by 5 bingo cards\n",
    "    bingo_card_numbers = np.array(bingo_cards).reshape(-1, 5, 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BingoCard:\n",
    "    \n",
    "    def __init__(self, values):\n",
    "        self.values = values  # 2D array\n",
    "        self.marked = np.zeros(shape=self.values.shape)  # Keep track of numbers that we marked\n",
    "        self.card_size = self.values.shape[0]  # Assumes square card\n",
    "        self.latest_value = None  # Needed for calculating the final answer\n",
    "        \n",
    "    def mark_number(self, value):\n",
    "        self.latest_value = value\n",
    "        # Mark a 1 on the indexes where we have a hit\n",
    "        if value in self.values:\n",
    "            self.marked[np.where(self.values==value)] = 1\n",
    "            \n",
    "    def check_for_bingo(self):\n",
    "        # If the sum of a row/column is the same as the size of the card we have a bingo\n",
    "        # Diagonals are not counted so this is easy\n",
    "        return self.card_size in self.marked.sum(axis=0) or self.card_size in self.marked.sum(axis=1)\n",
    "    \n",
    "    def calculate_answer(self):\n",
    "        # Sum of unmarked values * latest called value\n",
    "        return self.values[self.marked == 0].sum() * self.latest_value\n",
    "    \n",
    "    def calculate_n_moves_until_win(self, bingo_numbers):\n",
    "        \"\"\" Needed for part 2 \"\"\"\n",
    "        for n, number in enumerate(bingo_numbers):\n",
    "            self.mark_number(number)\n",
    "            if self.check_for_bingo():\n",
    "                return n, self.calculate_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38913"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bingo_cards = [BingoCard(card) for card in bingo_card_numbers]\n",
    "\n",
    "for number in numbers:\n",
    "    # Fill number on card\n",
    "    # Dont assign to variable as we're updating class instances\n",
    "    [card.mark_number(number) for card in bingo_cards]\n",
    "    \n",
    "    # Check for bingos\n",
    "    bingo_checks = [card.check_for_bingo() for card in bingo_cards]\n",
    "    \n",
    "    # If we have bingo there will be a true in this list, we check this with any\n",
    "    if any(bingo_checks):\n",
    "        # Winning card is the index of True\n",
    "        winning_card = bingo_cards[bingo_checks.index(True)]\n",
    "        break\n",
    "        \n",
    "winning_card.calculate_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "bingo_cards = [BingoCard(card) for card in bingo_card_numbers]\n",
    "\n",
    "# Get list of tuples containing amount of moves until win, and the score of the card\n",
    "moves_til_win = [card.calculate_n_moves_until_win(numbers) for card in bingo_cards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16836"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting ascendingly on n moves and taking the 1nd index we have our answer\n",
    "sorted(moves_til_win, key=lambda tup: tup[0])[-1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = read_input('day_5/input.txt')\n",
    "\n",
    "# Coordinates is array of [[x1, y1], [x2, y2]] pairs\n",
    "coordinates = np.array([[l.strip().split(',') for l in line.split('->')] for line in coordinates]).astype(int)\n",
    "\n",
    "# Only keep coordinates where x1 == x2 or y1 == y2\n",
    "hor_ver_coordinates = coordinates[(coordinates[:, 0, 0] == coordinates[:, 1, 0]) |\n",
    "                                  (coordinates[:, 0, 1] == coordinates[:, 1, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_empty_map(coordinates):\n",
    "    # Using coordinates calculate max map size\n",
    "    max_x = coordinates[:, :, 0].max()+1\n",
    "    max_y = coordinates[:, :, 1].max()+1\n",
    "    # Initialize empty map with all zeros\n",
    "    return np.zeros(shape=(max_y, max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = generate_empty_map(hor_ver_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x1, y1), (x2, y2) in hor_ver_coordinates:\n",
    "    if x1 == x2 or y1 == y2:\n",
    "        # Draw lines in the map by adding one\n",
    "        # Using min and max we prevent slicing from high to low value, numpy\n",
    "        # returns an empty array when we do that\n",
    "        map_[min(y1, y2): max(y1, y2)+1, min(x1, x2): max(x1, x2)+1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5280"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By counting all places where the value is higher than one we get our answer\n",
    "len(np.where(map_ > 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = generate_empty_map(coordinates)\n",
    "\n",
    "for (x1, y1), (x2, y2) in coordinates:\n",
    "    # Horizontal/vertical line\n",
    "    if x1 == x2 or y1 == y2:\n",
    "        # Draw lines in the map by adding one\n",
    "        # Using min and max we prevent slicing from high to low value, numpy\n",
    "        # returns an empty array when we do that\n",
    "        map_[min(y1, y2): max(y1, y2)+1, min(x1, x2): max(x1, x2)+1] += 1\n",
    "    # Diagonal line\n",
    "    else:\n",
    "        # Cannot use the min/max trick for both x and y coordinates as this will result\n",
    "        # in a flipped diagonal. We can simply fix this by using a negative stepsize, which\n",
    "        # will result in a reversed range, and therefore no flipped lines\n",
    "        x_stepsize = 1 if x2 > x1 else -1\n",
    "        y_stepsize = 1 if y2 > y1 else -1\n",
    "\n",
    "        # Because we also used to add 1 to the highest x and y, we need to substract\n",
    "        # one from the lowest x and y if we have a reversed range, otherwise the lines\n",
    "        # will be one too short\n",
    "        x2 = x2 - 1 if x2 < x1 else x2 + 1\n",
    "        y2 = y2 - 1 if y2 < y1 else y2 + 1\n",
    "        for x, y in zip(range(x1, x2, x_stepsize), range(y1, y2, y_stepsize)):\n",
    "            map_[y][x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16716"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(map_ > 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanternfish_timers = read_input('day_6/input.txt')[0].split(',')\n",
    "lanternfish_timers = np.array(lanternfish_timers).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_days = 80\n",
    "\n",
    "def lanternfish_model(original_population, n_days):\n",
    "    \"\"\" Given an initial population and an amount of days, returns the\n",
    "    amount of lanternfish after n_days days. \"\"\"\n",
    "    original_population = np.array([i for i in original_population])\n",
    "    for day in range(n_days):\n",
    "        # Subtract 1 from every timer\n",
    "        original_population -= 1\n",
    "\n",
    "        # Calculate amount of new lanternfishes by counting the amount of -1 timers\n",
    "        zero_timers = np.where(original_population == -1)[0]\n",
    "\n",
    "        if zero_timers.size > 0:\n",
    "            # Add new lanternfish with timer 8 for every original timer that hits -1\n",
    "            original_population = np.concatenate((original_population, np.full(len(zero_timers), 8)))\n",
    "\n",
    "            # Reset -1 fishes to 6\n",
    "            original_population[zero_timers] = 6\n",
    "    \n",
    "    return original_population.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354564"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lanternfish_model(lanternfish_timers, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1609058859115"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Above method grows exponentially so it doesnt work for large amount of days\n",
    "# New method uses a list of counts where the index is the timer of the fishes\n",
    "counts = [list(lanternfish_timers).count(i) for i in range(9)]\n",
    "\n",
    "for _ in range(256):\n",
    "    # Shift all items in count list to the left, the first element becomes\n",
    "    # the last element (fishes with timer 8)\n",
    "    counts = counts[1:] + [counts[0]]\n",
    "    # Because the original timer 0 fishes dont die, we have to\n",
    "    # add their count to index 6, because that is their timer after\n",
    "    # multiplying\n",
    "    counts[6] += counts[-1]\n",
    "\n",
    "sum(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "crab_positions = read_input(\"day_7/input.txt\")[0].split(',')\n",
    "crab_positions = np.array(crab_positions).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_constant_fuel_cost(crab_pos, target):\n",
    "    return sum(abs(crab_positions - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336120"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brute force as the data is not THAT big\n",
    "costs = [(target, calculate_constant_fuel_cost(crab_positions, target)) for target in range(max(crab_positions))]\n",
    "sorted(costs, key=lambda tup: tup[1])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_linear_fuel_cost(crab_pos, target):\n",
    "    \"\"\" Uses triangle numbers to calculate the costs \"\"\"\n",
    "    return sum((abs(crab_positions - target) * (abs(crab_positions - target) + 1)) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96864235.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brute force still works fast enough\n",
    "costs = [(target, calculate_linear_fuel_cost(crab_positions, target)) for target in range(max(crab_positions))]\n",
    "sorted(costs, key=lambda tup: tup[1])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = read_input(\"day_8/input.txt\")\n",
    "signals = [line.split('|') for line in signals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = [s[1] for s in signals]\n",
    "\n",
    "# Simply count the amount a token of length 2/3/4/7 occurs\n",
    "sum([len(s) in [2, 3, 4, 7] for s in ' '.join(outputs).split(' ')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = [''.join(s) for s in signals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logic from https://imgur.com/a/LIS2zZr\n",
    "\n",
    "- len(2) == 1\n",
    "- len(4) == 4\n",
    "- len(3) == 7\n",
    "- len(7) == 8\n",
    "- len(5) == [2, 3, 5]\n",
    "    - contains(7) == 3\n",
    "    - len(insersection(4) == 3) == 5\n",
    "    - else 2\n",
    "- len(6) == [0, 6, 9]\n",
    "    - contains(4) == 9\n",
    "    - contains(7) == 0\n",
    "    - else 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_charset(token):\n",
    "    return set([c for c in token])\n",
    "\n",
    "def charset_by_length(line, length):\n",
    "    \"\"\" Used for getting set of the characters in codes for 1, 4, 7, and 8 \"\"\"\n",
    "    return set([[c for c in code] for code in line if len(code) == length][0])\n",
    "\n",
    "def decode_line(line):\n",
    "    # Dictionary foor looking up a number by length (for the numbers 1, 4, 7, 8)\n",
    "    len_dict = {2: 1, 3: 7, 4: 4, 7: 8}\n",
    "\n",
    "    # Dictionary with sets of characters for known numbers 1, 4, 7, and 8, using the\n",
    "    # keys and values from len_dict\n",
    "    char_dict = {k: charset_by_length(line, l) for l, k in len_dict.items()}\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    # Decoding using a for loop\n",
    "    for token in line:\n",
    "        charset = token_to_charset(token)\n",
    "        # Simple lookup by length\n",
    "        if len(charset) in [2, 3, 4, 7]:\n",
    "            decoded_tokens.append(len_dict[len(charset)])\n",
    "        # Length of 5 means 2, 3 or 5\n",
    "        elif len(charset) == 5:\n",
    "            # If the token contains all characters used by 7\n",
    "            # the token is a three\n",
    "            if char_dict[7].issubset(charset):\n",
    "                decoded_tokens.append(3)\n",
    "            # If the intersection of the characters is of size\n",
    "            # 3 the token is a 5\n",
    "            elif len(char_dict[4].intersection(charset)) == 3:\n",
    "                decoded_tokens.append(5)\n",
    "            # Only possible value is a 2\n",
    "            else:\n",
    "                decoded_tokens.append(2)\n",
    "        # Length of 6 means 9, 0, or 6\n",
    "        elif len(charset) == 6:\n",
    "            # If the token contains all characters used by 4, the\n",
    "            # token is a nine\n",
    "            if char_dict[4].issubset(charset):\n",
    "                decoded_tokens.append(9)\n",
    "            # Same trick as above for the characters of 7, the token\n",
    "            # is a 0\n",
    "            elif char_dict[7].issubset(charset):\n",
    "                decoded_tokens.append(0)\n",
    "            # Final option a 6\n",
    "            else:\n",
    "                decoded_tokens.append(6)\n",
    "\n",
    "    # Only return the final 4 values as integer, the rest is not needed for solution\n",
    "    return int(''.join([str(i) for i in decoded_tokens[-4:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040429"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([decode_line(line.split()) for line in signals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('day_9/input.txt', 'r') as f:\n",
    "    heatmap = [[int(c) for c in line.strip()] for line in f.readlines()]\n",
    "    \n",
    "width = len(heatmap[0])\n",
    "height = len(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_spot_values = []\n",
    "\n",
    "# Simply march over every spot on the map and check if the spot is a low spot\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        curr_value = heatmap[y][x]\n",
    "        # Hardcode the 4 points that we want to check\n",
    "        #                  up        down      left      right\n",
    "        coords_to_check = [[y-1, x], [y+1, x], [y, x-1], [y, x+1]]\n",
    "        # By default assume the spot is a low point, we set this boolean to False\n",
    "        # if we find a surrounding spot that is as low or lower as the current spot\n",
    "        # we're looking at\n",
    "        is_low_point = True\n",
    "        for y_, x_ in coords_to_check:\n",
    "            # Simply ignore index errors instead of manually checking for\n",
    "            # edges and corners\n",
    "            try:\n",
    "                if heatmap[y_][x_] <= curr_value:\n",
    "                    is_low_point = False\n",
    "                    # Stop iterating as we already know the spot is not a low spot\n",
    "                    break\n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "        if is_low_point:\n",
    "            low_spot_values.append(curr_value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer is the sum of all low spots + 1\n",
    "sum(low_spot_values) + len(low_spot_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('day_10/input.txt', 'r') as f:\n",
    "    chunks = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_brackets = ['{', '[', '(', '<']\n",
    "closing_brackets = ['}', ']', ')', '>']\n",
    "opening_bracket_dict = {k: v for k, v in zip(opening_brackets, closing_brackets)}\n",
    "closing_bracket_dict = {k: v for k, v in zip(closing_brackets, opening_brackets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_corrupted_line(line):\n",
    "    to_close = []\n",
    "    \n",
    "    for char in line:\n",
    "        # For every opening bracket we must find a closing bracket, otherwise\n",
    "        # the line is currupt\n",
    "        if char in opening_brackets:\n",
    "            to_close.append(char)\n",
    "        # If we find a closing bracket it must be for the last found\n",
    "        # opening bracket, if this is not true the line is corrupt\n",
    "        # and we return the corrupting character\n",
    "        elif char in closing_brackets:\n",
    "            if to_close[-1] == closing_bracket_dict[char]:\n",
    "                to_close.pop(-1)\n",
    "            else:\n",
    "                return char\n",
    "\n",
    "\n",
    "illegal_char_cost = {k: v for k, v in zip([')', ']', '}', '>'], [3, 57, 1197, 25137])}\n",
    "            \n",
    "illegal_chars = [parse_corrupted_line(line) for line in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362271"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([illegal_char_cost[c] for c in illegal_chars if c is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[')', '}', '>', ']', '}', ')']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete_line(line):\n",
    "    to_close = []\n",
    "    for char in line:\n",
    "        # Same logic as part 1, without stopping if we find a corrupt character (because\n",
    "        # we can assume these lines are not ccorrupted)\n",
    "        if char in opening_brackets:\n",
    "            to_close.append(char)\n",
    "        elif char in closing_brackets:\n",
    "            if to_close[-1] == closing_bracket_dict[char]:\n",
    "                to_close.pop(-1)\n",
    "                \n",
    "    # Output is the closing brackets for the brackets in to_close, reversed\n",
    "    return [opening_bracket_dict[c] for c in to_close[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_line(line):\n",
    "    score = 0\n",
    "    for i in line:\n",
    "        score *= 5\n",
    "        score += i\n",
    "    return score\n",
    "\n",
    "illegal_char_cost = {k: v for k, v in zip([')', ']', '}', '>'], [1, 2, 3, 4])}\n",
    "\n",
    "completions = [complete_line(line) for line in chunks if parse_corrupted_line(line) is None]\n",
    "completion_scores = [score_line([illegal_char_cost[c] for c in line]) for line in completions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698395182"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(completion_scores)[len(completion_scores) //2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day_11/input.txt\", 'r') as f:\n",
    "    octopi = np.array([[int(c) for c in line.strip()] for line in f.readlines()])\n",
    "    \n",
    "height = len(octopi)\n",
    "width = len(octopi[0])\n",
    "\n",
    "# Pad array with a large negative value so we dont have to worry about\n",
    "# index errors around the edges\n",
    "octopi = np.pad(octopi, 1, 'constant', constant_values=-10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1594"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_flashes = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # Default add 1 to every value at the start of step\n",
    "    octopi += 1\n",
    "    \n",
    "    # List to keep track of all flashes octopi, they can only flash once\n",
    "    flashed = []\n",
    "    # List of tuple y, x coordinates where an octopi has flashed\n",
    "    flashes = list(zip(*np.where(octopi > 9)))\n",
    "    # While we have flashing octopi\n",
    "    while flashes:\n",
    "        # Save flashed octopi to the list so that they wont flash again\n",
    "        flashed.extend(flashes)\n",
    "        # Add 1 to every octopi around a flashing octupus\n",
    "        for y_, x_ in flashes:\n",
    "            octopi[y_-1:y_+2, x_-1: x_+2] += 1\n",
    "\n",
    "        # Find new octopi that are going to flash, ignoring the ones that have already flashed\n",
    "        flashes = [tup for tup in list(zip(*np.where(octopi > 9))) if tup not in flashed]\n",
    "    # Reset counter for all flashed octopi\n",
    "    octopi[octopi > 9] = 0\n",
    "    # Keep track of amount of flashes for the answer\n",
    "    total_flashes += len(flashed)\n",
    "    \n",
    "total_flashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    # Default add 1 to every value at the start of step\n",
    "    octopi += 1\n",
    "    \n",
    "    # List to keep track of all flashes octopi, they can only flash once\n",
    "    flashed = []\n",
    "    # List of tuple y, x coordinates where an octopi has flashed\n",
    "    flashes = list(zip(*np.where(octopi > 9)))\n",
    "    # While we have flashing octopi\n",
    "    while flashes:\n",
    "        # Save flashed octopi to the list so that they wont flash again\n",
    "        flashed.extend(flashes)\n",
    "        # Add 1 to every octopi around a flashing octupus\n",
    "        for y_, x_ in flashes:\n",
    "            octopi[y_-1:y_+2, x_-1: x_+2] += 1\n",
    "\n",
    "        # Find new octopi that are going to flash, ignoring the ones that have already flashed\n",
    "        flashes = [tup for tup in list(zip(*np.where(octopi > 9))) if tup not in flashed]\n",
    "    # Reset counter for all flashed octopi\n",
    "    octopi[octopi > 9] = 0\n",
    "    \n",
    "    if octopi[1: height+1, 1: width+1].sum() == 0:\n",
    "        print(step + 1)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day_12/input.txt\", 'r') as f:\n",
    "    edges = [line.strip().split('-') for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = {}\n",
    "for from_, to in edges:\n",
    "    if from_ not in connections:\n",
    "        connections[from_] = []\n",
    "    if to not in connections:\n",
    "        connections[to] = []\n",
    "    connections[from_].append(to)\n",
    "    connections[to].append(from_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4775"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def paths(curr, seen):\n",
    "    if curr == 'end':\n",
    "        return 1\n",
    "    # Can only visit once\n",
    "    if curr.islower() and curr in seen:\n",
    "        return 0\n",
    "    seen = seen | {curr}\n",
    "    out = 0\n",
    "    for cave in connections[curr]:\n",
    "        out += paths(cave, seen)\n",
    "    return out\n",
    "\n",
    "paths(\"start\", set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152480"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def paths(curr, seen, dup):\n",
    "    if curr == 'end':\n",
    "        return 1\n",
    "    if curr == \"start\" and seen:\n",
    "        return 0\n",
    "    if curr.islower() and curr in seen:\n",
    "        if dup is None:\n",
    "            dup = curr\n",
    "        else:\n",
    "            return 0\n",
    "    seen = seen | {curr}\n",
    "    out = 0\n",
    "    for cave in connections[curr]:\n",
    "        out += paths(cave, seen, dup)\n",
    "    return out\n",
    "\n",
    "paths(\"start\", set(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day_13/input.txt\", 'r') as f:\n",
    "    coordinates, instructions = f.read().split('\\n\\n')\n",
    "coordinates = np.array([[int(c) for c in line.split(',')] for line in coordinates.split('\\n')])\n",
    "instructions = [line.split('=') for line in instructions.split('\\n')][:-1]\n",
    "instructions = [[l[0][-1], int(l[1])] for l in instructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_paper(paper, axis, value):\n",
    "    if axis == 'x':\n",
    "        paper = paper[:, :value] + np.flip(paper[:, value + 1:], axis=1)\n",
    "    else:\n",
    "        paper = paper[:value, :] + np.flip(paper[value + 1:, :], axis=0)\n",
    "    paper = np.clip(paper, 0, 1)\n",
    "    \n",
    "    # Have paper always have odd dimensions, otherwise flip doesnt work because of\n",
    "    # different array shapes\n",
    "    if len(paper) % 2 == 0:\n",
    "        paper = np.vstack([paper, np.zeros(len(paper[0]))])\n",
    "        \n",
    "    if len(paper[0]) % 2 == 0:\n",
    "        paper = np.hstack([paper, np.zeros(len(paper)).reshape(-1, 1)])\n",
    "    \n",
    "    return paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755.0"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper = np.zeros(shape=(coordinates[:, 1].max() + 1, coordinates[:, 0].max() + 1))\n",
    "paper[coordinates[:, 1], coordinates[:, 0]] = 1\n",
    "\n",
    "for axis, value in instructions[:1]:\n",
    "    paper = fold_paper(paper, axis, value)\n",
    "    \n",
    "\n",
    "paper.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = np.zeros(shape=(coordinates[:, 1].max() + 1, coordinates[:, 0].max() + 1))\n",
    "paper[coordinates[:, 1], coordinates[:, 0]] = 1\n",
    "\n",
    "\n",
    "for axis, value in instructions:\n",
    "    paper = fold_paper(paper, axis, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###  #    #  #   ## ###  ###   ##   ##   \n",
      "#  # #    # #     # #  # #  # #  # #  #  \n",
      "###  #    ##      # #  # ###  #  # #     \n",
      "#  # #    # #     # ###  #  # #### # ##  \n",
      "#  # #    # #  #  # # #  #  # #  # #  #  \n",
      "###  #### #  #  ##  #  # ###  #  #  ###  \n",
      "                                         \n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([''.join(row) for row in paper.astype(int).astype(str).tolist()]).replace('1', '#').replace('0', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open(\"day_14/input.txt\", 'r') as f:\n",
    "    template, rules = f.read().split(\"\\n\\n\")\n",
    "rules = [line.split(' -> ') for line in rules.split('\\n')][:-1]\n",
    "rules = {line[0]: line[1] for line in rules}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    new = \"\"\n",
    "\n",
    "    for c1, c2 in zip(template[:-1], template[1:]):\n",
    "        new += c1 + rules[c1+c2]\n",
    "    new += template[-1]\n",
    "    template = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2712"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(template).most_common(99)\n",
    "count[0][1] - count[-1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(\"day_14/input.txt\", 'r') as f:\n",
    "    template, _ = f.read().split(\"\\n\\n\")\n",
    "\n",
    "pair_dict = defaultdict(int)\n",
    "char_count = Counter(template)\n",
    "\n",
    "# Count pairs instead of keeping whole string in memory\n",
    "for c1, c2 in zip(template[:-1], template[1:]):\n",
    "    pair_dict[c1+c2] += 1\n",
    "\n",
    "    \n",
    "for _ in range(40):\n",
    "    for pair, count in pair_dict.copy().items():\n",
    "        # Because we're splitting the pair in two it should be removed from the pair count\n",
    "        pair_dict[pair] -= count\n",
    "        # Add count of original pair to both new pairs that happen when inserting new character\n",
    "        pair_dict[pair[0]+rules[pair]] += count\n",
    "        pair_dict[rules[pair]+pair[1]] += count\n",
    "        # Also update the count of the new characters we added to the 'string'\n",
    "        char_count[rules[pair]] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8336623059567"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_count = sorted(char_count.items(), key=lambda tup: tup[1])\n",
    "char_count[-1][1] - char_count[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "with open('day_15/input.txt', 'r') as f:\n",
    "    map_ = [[int(c) for c in line.strip()] for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_from_map(map_):\n",
    "    \"\"\" Simply transform the map into a directed networkx graph so we can use the builtin\n",
    "    shortest path function to calculate the sum of the safest path. \"\"\"\n",
    "    width = len(map_[0])\n",
    "    height = len(map_)\n",
    "    \n",
    "    edge_list = []\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            curr = f\"{y}-{x}\"\n",
    "                        # Top     # Bottom   # Left    # Right\n",
    "            to_visit = [(y-1, x), (y+1, x), (y, x-1), (y, x+1)]\n",
    "            for y_, x_ in to_visit:\n",
    "                if y_ >= 0 and x_ >= 0 and y_ < height and x_ < width:\n",
    "                    edge_list.append((curr, f\"{y_}-{x_}\", map_[y_][x_]))        \n",
    "    \n",
    "    g = nx.DiGraph()\n",
    "    g.add_weighted_edges_from(edge_list)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = network_from_map(map_)\n",
    "shortest_path_coords = [coords.split('-') for coords in nx.shortest_path(g, '0-0', f\"{height-1}-{width-1}\", weight='weight')]\n",
    "\n",
    "\n",
    "sum([map_[int(y)][int(x)] for y, x in shortest_path_coords[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = np.array(map_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_map = [[[] for _ in range(5)] for _ in range(5)]\n",
    "large_map[0][0] = map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_map(map_):\n",
    "    new_map = map_ + 1\n",
    "    new_map[new_map > 9] = 1\n",
    "    return new_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(5):\n",
    "    if y == 0:\n",
    "        pass\n",
    "    else:\n",
    "        large_map[y][0] = transform_map(large_map[y-1][0])\n",
    "    for x in range(1, 5):\n",
    "        large_map[y][x] = transform_map(large_map[y][x-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat all rows and finally stack the rows on top of eachother to get the map\n",
    "map_ = np.vstack([np.hstack(row) for row in large_map])\n",
    "map_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2806"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = network_from_map(map_)\n",
    "shortest_path_coords = [coords.split('-') for coords in\n",
    "                        nx.shortest_path(g, '0-0', f\"{map_.shape[0]-1}-{map_.shape[1]-1}\", weight='weight')]\n",
    "\n",
    "\n",
    "sum([map_[int(y)][int(x)] for y, x in shortest_path_coords[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day_16/input.txt\", 'r') as f:\n",
    "    hexcode = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_num = {str(i): bin(i)[2:].zfill(4) for i in range(10)}\n",
    "decoding_char = {tup[0]: bin(tup[1])[2:].zfill(4) for tup in zip(\"ABCDEF\", [i for i in range(10, 16)])}\n",
    "decoding = {**decoding_num, **decoding_char}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = ''.join([decoding[c] for c in hexcode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_sum = 0\n",
    "\n",
    "\n",
    "def parse(data):\n",
    "    global version_sum\n",
    "    # First 3 bits are version\n",
    "    version = int(data[:3], 2)\n",
    "    version_sum += version\n",
    "    # We parsed version so we can remove it from the data\n",
    "    data = data[3:]\n",
    "    \n",
    "    # Same trick as above for getting version\n",
    "    type_ = int(data[:3], 2)\n",
    "    data = data[3:]\n",
    "    \n",
    "    # Part 1 doesnt need anything done for type four as long as we saved the version\n",
    "    if type_ == 4:\n",
    "        while True:\n",
    "            keep_going = data[0]\n",
    "            data = data[5:]\n",
    "            if keep_going == '0':\n",
    "                break\n",
    "    else:\n",
    "        length_type_id = data[0]\n",
    "        data = data[1:]\n",
    "        # Recursively parse the subparts using the defined length type id\n",
    "        if length_type_id == '0':\n",
    "            subp_length = int(data[:15], 2)\n",
    "            data = data[15:]\n",
    "            subp = data[:subp_length]\n",
    "            while subp:\n",
    "                subp = parse(subp)\n",
    "            data = data[subp_length:]\n",
    "        else:\n",
    "            n_subp = int(data[:11], 2)\n",
    "            data = data[11:]\n",
    "            for _ in range(n_subp):\n",
    "                data = parse(data)\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = parse(decoded)\n",
    "version_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('target area: x=150..171, y=-129..-70', 150, 171, -129, -70)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"day_17/input.txt\", 'r') as f:\n",
    "    target_area = f.read().strip()\n",
    "    \n",
    "xl, xr, yb, yt = [int(i) for i in re.findall(r'-?\\d+', target_area)]\n",
    "target_area, xl, xr, yb, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj(xv, yv):\n",
    "    max_ypos = 0\n",
    "    xpos, ypos = 0, 0\n",
    "    # As long as we are not overshooting keep going\n",
    "    while xpos <= xr and ypos >= yb:\n",
    "        xpos += xv\n",
    "        ypos += yv\n",
    "        xv -= 1 if xv > 0 else -1 if xv < 0 else 0\n",
    "        yv -= 1\n",
    "        \n",
    "        if ypos > max_ypos:\n",
    "            max_ypos = ypos\n",
    "        # Check if we are in target zone\n",
    "        if xpos >= xl and xpos <= xr and ypos >= yb and ypos <= yt:\n",
    "            return True, max_ypos\n",
    "        \n",
    "    return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x pos converges after xv steps, so we first brute-force the valid initial x velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xpos_convergence(n):\n",
    "    \"\"\" Basically triangle number. \"\"\"\n",
    "    return sum([i for i in range(1, n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 18]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv = 0\n",
    "valid_xvs = []\n",
    "while True:\n",
    "    # Keep track of amount of valid x velocities; this is used for stopping the loop\n",
    "    # when we are overshooting\n",
    "    curr_len = len(valid_xvs)\n",
    "    final_xpos = xpos_convergence(xv)\n",
    "    # If convergence is in target we save the x velocity\n",
    "    if final_xpos >= xl and final_xpos <= xr:\n",
    "        valid_xvs.append(xv)\n",
    "    xv += 1\n",
    "    \n",
    "    # If we already added to list and the length hasnt changed we are overshooting the target\n",
    "    # and we can stop finding x velocities\n",
    "    if len(valid_xvs) and len(valid_xvs) == curr_len:\n",
    "        break\n",
    "\n",
    "valid_xvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_shots = []\n",
    "\n",
    "for xv in valid_xvs:\n",
    "    for yv in range(1000):\n",
    "        valid_traj, max_ypos = traj(xv, yv)\n",
    "        if valid_traj:\n",
    "            valid_shots.append((xv, yv, max_ypos))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(valid_shots, key=lambda tup: tup[2])[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 134.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Rather wait a few seconds brute forcing instead of using math to find all succesful velocities\n",
    "\n",
    "good_init_velocities = 0\n",
    "\n",
    "for xv in tqdm(range(1000)):\n",
    "    for yv in range(-1000, 1000):\n",
    "        valid_traj, _ = traj(xv, yv)\n",
    "        if valid_traj:\n",
    "            good_init_velocities += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2326"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_init_velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def calc_output_pixel(arr):\n",
    "    bytes_ = ''.join(arr.flatten().astype(str).tolist())\n",
    "    idx = int(bytes_, 2)\n",
    "    return enhancement_string[idx]\n",
    "\n",
    "\n",
    "def print_img(img):\n",
    "    print('\\n'.join([''.join(line) for line in img.astype(str)]).replace('0', '.').replace('1', '#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day_20/input.txt\") as f:\n",
    "    enhancement_string, img = f.read().split(\"\\n\\n\")\n",
    "        \n",
    "img = img.replace('.', '0').replace('#', '1').strip().split('\\n')\n",
    "img = np.array([[int(c) for c in line] for line in img])\n",
    "\n",
    "enhancement_string = enhancement_string.replace('.', '0').replace('#', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_image(img, n_steps):\n",
    "    # Pad image by 5 to keep some buffer for expanding\n",
    "    img = np.pad(img, 5, 'constant', constant_values=0)\n",
    "    \n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        # Pad 'infinite' image with 2 rows/columns containing the values of the edge\n",
    "        # This handles potential growth of the image while keeping an extra buffer that we will\n",
    "        # trim off later, as our for loop wont update the edges\n",
    "        img = np.pad(img, 2, 'edge')\n",
    "\n",
    "        # Place to store new values\n",
    "        new_img = img.copy()\n",
    "\n",
    "        # Iterate over whole image except the edges to prevent index errors\n",
    "        for y in range(1, len(img)-1):\n",
    "            for x in range(1, len(img[0]) - 1):\n",
    "                new_img[y, x] = calc_output_pixel(img[y-1:y+2, x-1:x+2])\n",
    "\n",
    "        # Trim away the edges we did not iterate over\n",
    "        img = new_img[1:-1, 1:-1].copy()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5622"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_image(img, 2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  3.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20395"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Somehow code was fast enough to do part 2 aswell\n",
    "expand_image(img, 50).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"day_21/input.txt\") as f:\n",
    "    p1, p2 = [int(line[-1]) for line in f.read().strip().split(\"\\n\")]\n",
    "    \n",
    "p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicDice:\n",
    "    def __init__(self):\n",
    "        self.prev_roll = 0\n",
    "        self.n_rolls = 0\n",
    "        \n",
    "    def roll(self):\n",
    "        self.n_rolls += 1\n",
    "        \n",
    "        if self.prev_roll == 100:\n",
    "            self.prev_roll = 1\n",
    "        else:\n",
    "            self.prev_roll += 1\n",
    "        return self.prev_roll\n",
    "    \n",
    "    def sum_of_n_rolls(self, n=3):\n",
    "        return sum([self.roll() for _ in range(n)])\n",
    "    \n",
    "    \n",
    "class Board:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.p1_score = 0\n",
    "        self.p2_score = 0\n",
    "        self.winner = None\n",
    "        \n",
    "    def move(self, player, n):\n",
    "        if player == 1:\n",
    "            self.p1 = (self.p1 + n) % 10 if self.p1 + n != 10 else 10\n",
    "            self.p1_score += self.p1\n",
    "        else:\n",
    "            self.p2 = (self.p2 + n) % 10 if self.p2 + n != 10 else 10\n",
    "            self.p2_score += self.p2\n",
    "            \n",
    "    def check_for_winner(self):\n",
    "        if self.p1_score >= 1000:\n",
    "            self.winner = 1\n",
    "            return True\n",
    "        elif self.p2_score >= 1000:\n",
    "            self.winner = 2\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    \n",
    "dice = DeterministicDice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = DeterministicDice()\n",
    "board = Board(p1, p2)\n",
    "\n",
    "player = 0\n",
    "\n",
    "while board.winner is None:\n",
    "    roll = dice.sum_of_n_rolls(3)\n",
    "    board.move(player + 1, roll)\n",
    "    board.check_for_winner()\n",
    "    player = abs(player - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920580"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if board.winner == 1:\n",
    "    losing_score = board.p2_score\n",
    "else:\n",
    "    losing_score = board.p1_score\n",
    "    \n",
    "losing_score * dice.n_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
